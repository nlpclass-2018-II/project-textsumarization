{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import itertools\n",
    "import editdistance\n",
    "import nltk\n",
    "import textdistance\n",
    "import os\n",
    "\n",
    "def buildGraph(nodes):\n",
    "    graph = nx.Graph()\n",
    "    graph.add_nodes_from(nodes)\n",
    "    nodePairs = list(itertools.combinations(nodes, 2))\n",
    "\n",
    "    for pair in nodePairs:\n",
    "        firstString = pair[0]\n",
    "        secondString = pair[1]\n",
    "        distance = editdistance.eval(firstString, secondString)\n",
    "        graph.add_edge(firstString, secondString, weight=distance)\n",
    "\n",
    "    return graph\n",
    "\n",
    "def buildGraphAlt(nodes):\n",
    "    graph = nx.Graph()\n",
    "    graph.add_nodes_from(nodes)\n",
    "    nodePairs = list(itertools.combinations(nodes, 2))\n",
    "\n",
    "    for pair in nodePairs:\n",
    "        firstString = pair[0]\n",
    "        secondString = pair[1]\n",
    "        distance = textdistance.hamming.distance(firstString,secondString) #https://pypi.org/project/textdistance/ for other distance\n",
    "        graph.add_edge(firstString, secondString, weight=distance)\n",
    "\n",
    "    return graph\n",
    "\n",
    "def summarize(text, sentenceCount):\n",
    "    file = open(text)\n",
    "    text = file.read()\n",
    "    sentences = nltk.tokenize.sent_tokenize(text)\n",
    "    graph = buildGraph(sentences)\n",
    "\n",
    "    scoredSentences = nx.pagerank(graph, weight='weight')\n",
    "    rankedSentences = sorted( ((value, key) for (key,value) in scoredSentences.items()),reverse=True)\n",
    "    \n",
    "    summary = ''\n",
    "    for i in range(0, sentenceCount):\n",
    "        summary = summary + rankedSentences[i][1] + '\\n\\n'\n",
    "        \n",
    "    return summary\n",
    "\n",
    "def summarizeAlt(text, sentenceCount):\n",
    "    file = open(text)\n",
    "    text = file.read()\n",
    "    sentences = nltk.tokenize.sent_tokenize(text)\n",
    "    graph = buildGraphAlt(sentences)\n",
    "\n",
    "    scoredSentences = nx.pagerank(graph, weight='weight')\n",
    "    rankedSentences = sorted( ((value, key) for (key,value) in scoredSentences.items()),reverse=True)\n",
    "    rankedSentences\n",
    "    \n",
    "    summary = ''\n",
    "    for i in range(0, sentenceCount):\n",
    "        summary = summary + rankedSentences[i][1] + '\\n\\n'\n",
    "\n",
    "    return summary\n",
    "\n",
    "def writeSummary(summary, text):\n",
    "    file = open(text + ' Summary.txt', 'w+')\n",
    "    file.write(summary)\n",
    "    file.close()\n",
    "    \n",
    "def rogue(text, sentenceCount):\n",
    "    path = \"Gold/\"\n",
    "    file = open(path + text + ' Gold.txt')\n",
    "    goldSum = file.read()\n",
    "    goldSum = nltk.tokenize.word_tokenize(goldSum)\n",
    "\n",
    "    path = \"Text/\"\n",
    "    A = summarize(path + text + '.txt', sentenceCount)\n",
    "    B = summarizeAlt(path + text + '.txt', sentenceCount)\n",
    "    tokenA = nltk.tokenize.word_tokenize(A)\n",
    "    tokenB = nltk.tokenize.word_tokenize(B)\n",
    "\n",
    "    rogueCount = {}\n",
    "\n",
    "    totalword = 0\n",
    "    totalword2 = 0\n",
    "    # counting unigram words\n",
    "    for word in tokenA:\n",
    "        if word in goldSum:\n",
    "            totalword += 1\n",
    "\n",
    "    for word in tokenB:\n",
    "        if word in goldSum:\n",
    "            totalword2 += 1\n",
    "\n",
    "    rogueCount[1] = totalword / len(goldSum)\n",
    "    rogueCount[2] = totalword2 / len(goldSum)\n",
    "    \n",
    "    path = \"Summary/\"\n",
    "    if (rogueCount[1] > rogueCount[2]):\n",
    "        writeSummary(A, path + text)\n",
    "    else:\n",
    "        writeSummary(B, path + text)\n",
    "\n",
    "    return rogueCount\n",
    "\n",
    "def run(pattern, count):\n",
    "    i = 1\n",
    "    score = ''\n",
    "    for file in os.listdir('Text/'):\n",
    "        filename = pattern + ' 0' + str(i)\n",
    "        eval = rogue(filename, count)\n",
    "        score = score + \"Number \" + str(i) + \"   1: \" + str(eval[1]) + \"   2: \" + str(eval[1]) + \"\\n\"\n",
    "        i += 1\n",
    "\n",
    "    file = open('Score.txt', 'w+')\n",
    "    file.write(score)\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 1.097938144329897, 2: 1.0257731958762886}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval = rogue ('Test 02', 6)\n",
    "eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "run('Test', 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
